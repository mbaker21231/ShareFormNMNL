{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Arrangement\n",
    "\n",
    "Because the medicare data from cms is poorly labelled, it is hard to write a script to download it. But supposing you have downloaded penetration data and the county-state-plan subscription data, here is a workbook that unzips all the files and makes them into a single panel data set, and saves it in Stata form. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, glob, re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude = 'mjbaker'\n",
    "\n",
    "dir_name_1 = 'C:\\\\Users\\\\' + dude + '\\\\Documents\\\\Medicare\\\\Markets\\\\'\n",
    "dir_name_2 = 'C:\\\\Users\\\\' + dude + '\\\\Documents\\\\Medicare\\\\Shares\\\\'\n",
    "extension = \".zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir_name_1) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(dir_name_1):            # loop through items in dir\n",
    "    if item.endswith(extension):               # check for \".zip\" extension\n",
    "        file_name = os.path.abspath(item)      # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name)   # create zipfile object\n",
    "        zip_ref.extractall(dir_name_1)         # extract file to dir\n",
    "        zip_ref.close()                        # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir_name_2)\n",
    "\n",
    "for item in os.listdir(dir_name_2):\n",
    "    if item.endswith(extension):\n",
    "        file_name = os.path.abspath(item)\n",
    "        zip_ref = zipfile.ZipFile(file_name)\n",
    "        zip_ref.extractall(dir_name_2)\n",
    "        zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "os.chdir(dir_name_1)\n",
    "\n",
    "file_list_1 = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    file_list_1.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir_name_2)\n",
    "\n",
    "file_list_2 = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    file_list_2.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendata = pd.read_csv(dir_name_1 + file_list_1[0])\n",
    "pendata['fn'] = file_list_1[0]\n",
    "\n",
    "for file in file_list_1:\n",
    "    df = pd.read_csv(dir_name_1 + file)\n",
    "    df['fn'] = file\n",
    "    pendata = pendata.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Pickle...if previously made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237662.475324.713237.951155.1189435.1427774.1665374.1903414.2393560.2883863.3373795.3863219.4352283.4841683.5331169.5820494.6309929.6799186.7288466.7778162.8237184.8697074.9156317.9615433.10074526.10520028.10979413.11438897.11898667.12358379.12818199.13278865.13690062.14100568.14510731.14920373.15329147.15738408.16147741.16556698.16965769.17374539.17783438.18193401.18599097.19003627.19407393.19808767.20209839.20609616.21007892.21406811.21806330.22205315.22604276.23004725.23408002.23809869.24211454.24612365.25012666.25413609.25814461.26215524.26617540.27019500.27421272.27824791.28248601.28670547.29091403.29510828.29930432.30351255.30771933.31193113.31615531.32037730.32459828.32883656.33286947.33688644.34090380.34491370.34892271.35294055.35695664.36097354.36500373.36903221.37306156.37710598.38061664.38411058.38760624.39108925.39457008.39805819.40154199.40503017.40852715.41202272.41551980.41903102.42251001.42596332.42941888.43286212.43630216.43975162.44319463.44664236.45009831.45354706.45699556.46047118.46409755.46770991.47131944.47489954.47847486.48205973.48564164.48922056.49280706.49639117.49997280.50357367.50731455."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shrdata = pd.read_pickle('C:\\\\Users\\\\matthew\\\\downloads\\\\tempshr.pkl')\n",
    "    print('File exists and is read in...')\n",
    "except:\n",
    "    shrdata = pd.read_csv(dir_name_2 + file_list_2[0])\n",
    "    shrdata['fn'] = file_list_2[0]\n",
    "\n",
    "    for file in file_list_2:\n",
    "        print(len(shrdata), end='.')\n",
    "        df = pd.read_csv(dir_name_2 + file)\n",
    "        df['fn'] = file\n",
    "        shrdata = shrdata.append(df)\n",
    "    \n",
    "    shrdata.to_pickle('C:\\\\Users\\\\' + dude + '\\\\downloads\\\\tempshr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking a look at the data\n",
    "\n",
    "We first see that our data sets are quite long! Unfortunately, we need to make them a little longer by adding in information about the year and the month. Let's first see if we don't need some of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Contract ID</th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Organization Type</th>\n",
       "      <th>Plan Type</th>\n",
       "      <th>SSA Code</th>\n",
       "      <th>FIPS Code</th>\n",
       "      <th>Enrolled</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>90091</td>\n",
       "      <td>UNITED MINE WORKERS OF AMERICA HEALTH &amp; RETIRE...</td>\n",
       "      <td>HCPP - 1833 Cost</td>\n",
       "      <td>HCPP - 1833 Cost</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCC_Enrollment_MA_2008_06.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>E5088</td>\n",
       "      <td>DESERET HEALTHCARE EMPLOYEE BENEFITS TRUST</td>\n",
       "      <td>Employer/Union Only Direct Contract PFFS</td>\n",
       "      <td>Employer/Union Only Direct Contract PFFS</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCC_Enrollment_MA_2008_06.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>H0087</td>\n",
       "      <td>HEALTH ALLIANCE MEDICAL PLANS</td>\n",
       "      <td>PFFS</td>\n",
       "      <td>PFFS</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCC_Enrollment_MA_2008_06.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>H0104</td>\n",
       "      <td>BLUE CROSS AND BLUE SHIELD OF ALABAMA</td>\n",
       "      <td>Local CCP</td>\n",
       "      <td>Local PPO</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>SCC_Enrollment_MA_2008_06.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>H0150</td>\n",
       "      <td>HEALTHSPRING OF ALABAMA, INC.</td>\n",
       "      <td>Local CCP</td>\n",
       "      <td>HMO/HMOPOS</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>SCC_Enrollment_MA_2008_06.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    County State Contract ID  \\\n",
       "0  Autauga    AL       90091   \n",
       "1  Autauga    AL       E5088   \n",
       "2  Autauga    AL       H0087   \n",
       "3  Autauga    AL       H0104   \n",
       "4  Autauga    AL       H0150   \n",
       "\n",
       "                                   Organization Name  \\\n",
       "0  UNITED MINE WORKERS OF AMERICA HEALTH & RETIRE...   \n",
       "1         DESERET HEALTHCARE EMPLOYEE BENEFITS TRUST   \n",
       "2                      HEALTH ALLIANCE MEDICAL PLANS   \n",
       "3              BLUE CROSS AND BLUE SHIELD OF ALABAMA   \n",
       "4                      HEALTHSPRING OF ALABAMA, INC.   \n",
       "\n",
       "                          Organization Type  \\\n",
       "0                          HCPP - 1833 Cost   \n",
       "1  Employer/Union Only Direct Contract PFFS   \n",
       "2                                      PFFS   \n",
       "3                                 Local CCP   \n",
       "4                                 Local CCP   \n",
       "\n",
       "                                  Plan Type  SSA Code  FIPS Code  Enrolled  \\\n",
       "0                          HCPP - 1833 Cost      1000     1001.0       NaN   \n",
       "1  Employer/Union Only Direct Contract PFFS      1000     1001.0       NaN   \n",
       "2                                      PFFS      1000     1001.0       NaN   \n",
       "3                                 Local PPO      1000     1001.0     593.0   \n",
       "4                                HMO/HMOPOS      1000     1001.0     218.0   \n",
       "\n",
       "                              fn  \n",
       "0  SCC_Enrollment_MA_2008_06.csv  \n",
       "1  SCC_Enrollment_MA_2008_06.csv  \n",
       "2  SCC_Enrollment_MA_2008_06.csv  \n",
       "3  SCC_Enrollment_MA_2008_06.csv  \n",
       "4  SCC_Enrollment_MA_2008_06.csv  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the file names that we affixed to get a year and a date for each observation as we need this to merge on. In any event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "years  = [re.findall(r\"\\d{4}\", file)[0] for file in file_list_2]\n",
    "years  = [float(item) for item in years]\n",
    "\n",
    "months = [re.findall(r\"\\_\\d{2}\\.\", file)[0][1:3] for file in file_list_2]\n",
    "months = [float(item) for item in months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shr_data_year_dict = dict(zip(file_list_2, years))\n",
    "shr_data_mont_dict = dict(zip(file_list_2, months))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrdata['year'] = shrdata['fn'].map(shr_data_year_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrdata['month'] = shrdata['fn'].map(shr_data_mont_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrdata.drop(['fn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [re.findall(r\"\\d{4}\", file)[0] for file in file_list_1]\n",
    "years = [float(item) for item in years]\n",
    "\n",
    "months = [re.findall(r\"\\_\\d{2}\\.\", file)[0][1:3] for file in file_list_1]\n",
    "months = [float(item) for item in months]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_data_year_dict = dict(zip(file_list_1, years))\n",
    "pen_data_mont_dict = dict(zip(file_list_1, months))\n",
    "\n",
    "pendata['year']  = pendata['fn'].map(pen_data_year_dict)\n",
    "pendata['month'] = pendata['fn'].map(pen_data_mont_dict) \n",
    "\n",
    "pendata.drop(['fn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Data\n",
    "\n",
    "Before, we merged on state, county, and other stuff. I guess we could try this on the codes and all that. The problem is that there are FIPS codes that mix floats and strings. I don't trust them so I will just do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_match = {'Alabama':'AL', 'Alaska':'AK', 'American Samoa':'AS', 'Arizona':'AZ', 'Arkansas':'AR', 'California':'CA',\n",
    " 'Colorado':'CO', 'Connecticut':'CT', 'Delaware':'DE', 'District Of Columbia':'DC',\n",
    " 'Florida':'FL', 'Georgia':'GA', 'Guam':'GU', 'Hawaii':'HI', 'Idaho':'ID', 'Illinois':'IL',\n",
    " 'Indiana':'IN', 'Iowa':'IA', 'Kansas':'KS', 'Kentucky':'KY', 'Louisiana':'LA', 'Maine':'ME', 'Maryland':'MD', \n",
    " 'Massachusetts':'MA',\n",
    " 'Michigan':'MI', 'Minnesota':'MN', 'Mississippi':'MS', 'Missouri':'MO', 'Montana':'MT', 'Nebraska':'NE', 'Nevada':'NV', \n",
    " 'New Hampshire':'NH', 'New Jersey':'NJ', 'New Mexico':'NM',\n",
    " 'New York':'NY', 'North Carolina':'NC', 'North Dakota':'ND', 'Ohio':'OH',\n",
    " 'Oklahoma':'OK', 'Oregon':'OR', 'Pending State Designation':'GB', 'Pennsylvania':'PA', 'Puerto Rico':'PR', \n",
    " 'Rhode Island':'RI', 'South Carolina':'SC',\n",
    " 'South Dakota':'SD', 'Tennessee':'TN', 'Texas':'TX', 'Utah':'UT', 'Vermont':'VT', 'Virgin Islands':'VI',\n",
    " 'Virginia':'VA',\n",
    " 'Wake Island':'QW', 'Washington':'WA', 'Washington D.C.':'DC', 'West Virginia':'WV', 'Wisconsin':'WI', 'Wyoming':'WY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendata['State'] = pendata['State Name'].map(state_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendata.rename(columns={'County Name': 'County'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now should be able to merge on County, State, year and month...which will probably take a while! However, there seems to be just too much data to actually pull this off. So, let's try and drop nan variables. First, what do we gain by doing this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrdata['Enrolled'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrdata = shrdata.loc[shrdata['Enrolled'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrdata = pd.merge(shrdata, pendata, on=['State', 'County', 'year', 'month'], how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = shrdata[['County', 'State', 'year', 'month']].loc[shrdata['_merge'] == 'right_only']\n",
    "lo = shrdata[['County', 'State', 'year', 'month']].loc[shrdata['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateco = ro['County'] + ' ' + ro['State']\n",
    "stateco2 = lo['County'] + ' ' + lo['State']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the looks of the above, it seems as though most of the data from the left is out of the united states proper. It could be that no medicare advantage plans are offered in the rest of the places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = list(shrdata.select_dtypes(include=['object']).columns)\n",
    "\n",
    "for col in obj_cols:\n",
    "    shrdata[col] = shrdata[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrdata.to_stata('C:\\\\Users\\\\'+ dude+ '\\\\downloads\\\\medicare.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
